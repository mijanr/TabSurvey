# General parameters
dataset: fwht2_k128_s112_50k
model_name: DANet # LinearModel, KNN, SVM, DecisionTree, RandomForest, XGBoost, CatBoost, LightGBM, ModelTree
                # MLP, TabNet, VIME, TabTransformer, RLN, DNFNet, STG, NAM, DeepFM, SAINT
objective: regression # Don't change

optimize_hyperparameters: True

# GPU parameters
use_gpu: True
gpu_ids: [0] #[0, 1]
data_parallel: True

# Optuna parameters - https://optuna.org/
n_trials: 10
direction: minimize

# Cross validation parameters
num_splits: 5
shuffle: True
seed: 221 # Don't change

# Preprocessing parameters
scale: True
target_encode: False
one_hot_encode: False

# Training parameters
batch_size: 128
val_batch_size: 256
early_stopping_rounds: 20
epochs: 500
logging_period: 100

# About the data
num_classes: 1  # for classification
num_features: 128
# cat_idx: []
# # cat_dims: will be automatically set.
# cat_dims: [9, 16, 7, 15, 6, 5, 2, 42]